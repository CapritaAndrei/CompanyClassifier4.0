#!/usr/bin/env python3
"""
Similarity-Based Insurance Classifier
Instead of predicting 908 labels (impossible), find similar companies
"""

import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import json
from typing import Dict, List, Tuple


class SimilarityBasedClassifier:
    """
    A realistic approach that:
    1. Finds similar companies in training data
    2. Returns their labels with similarity scores
    3. Actually works with sparse data
    """
    
    def __init__(self, training_data_path: str = "data/processed/training_data.csv"):
        self.df = pd.read_csv(training_data_path)
        self.sentence_model = None
        self.company_embeddings = None
        self.initialize()
        
    def initialize(self):
        """Initialize the similarity model"""
        print("üß† Initializing similarity-based classifier...")
        
        # Load sentence transformer
        print("Loading semantic model...")
        self.sentence_model = SentenceTransformer('all-MiniLM-L6-v2')
        
        # Create embeddings for all training companies
        print("Creating embeddings for training data...")
        descriptions = []
        for idx, row in self.df.iterrows():
            # Combine description with business tags for better representation
            desc = str(row.get('description', '')).strip()
            tags = row.get('business_tags', '[]')
            
            if isinstance(tags, str) and tags.startswith('['):
                try:
                    tags = eval(tags)
                    tags_text = ' '.join(tags) if isinstance(tags, list) else ''
                except:
                    tags_text = ''
            else:
                tags_text = str(tags)
            
            # Combine description and tags
            combined_text = f"{desc} {tags_text}"
            descriptions.append(combined_text)
        
        # Create embeddings
        self.company_embeddings = self.sentence_model.encode(descriptions, show_progress_bar=True)
        print(f"‚úÖ Created embeddings for {len(self.company_embeddings)} companies")
        
    def find_similar_companies(self, company_data: Dict, top_k: int = 10) -> List[Dict]:
        """Find the most similar companies in training data"""
        
        # Create embedding for query company
        desc = company_data.get('description', '')
        tags = company_data.get('business_tags', [])
        
        if isinstance(tags, list):
            tags_text = ' '.join(tags)
        else:
            tags_text = str(tags)
            
        query_text = f"{desc} {tags_text}"
        query_embedding = self.sentence_model.encode([query_text])
        
        # Calculate similarities
        similarities = cosine_similarity(query_embedding, self.company_embeddings)[0]
        
        # Get top-k most similar
        top_indices = np.argsort(similarities)[-top_k:][::-1]
        
        results = []
        for idx in top_indices:
            similarity = similarities[idx]
            similar_company = self.df.iloc[idx]
            
            # Handle missing/NaN descriptions
            desc = similar_company.get('description', '')
            if pd.isna(desc) or not isinstance(desc, str):
                desc = 'No description available'
            
            # Handle missing business tags
            tags = similar_company.get('business_tags', '[]')
            if pd.isna(tags):
                tags = '[]'
            
            results.append({
                'label': similar_company['primary_label'],
                'similarity': float(similarity),
                'description': desc[:200] + '...' if len(desc) > 200 else desc,
                'business_tags': tags,
                'sector': similar_company.get('sector', 'Unknown')
            })
        
        return results
    
    def predict(self, company_data: Dict, top_k: int = 5) -> Dict:
        """Make prediction based on similar companies"""
        
        # Find similar companies
        similar_companies = self.find_similar_companies(company_data, top_k=20)
        
        # Aggregate labels from similar companies
        label_scores = {}
        for company in similar_companies:
            label = company['label']
            similarity = company['similarity']
            
            if pd.notna(label) and label != 'nan':
                if label not in label_scores:
                    label_scores[label] = {'score': 0, 'count': 0, 'max_similarity': 0}
                
                # Weight by similarity
                label_scores[label]['score'] += similarity
                label_scores[label]['count'] += 1
                label_scores[label]['max_similarity'] = max(
                    label_scores[label]['max_similarity'], 
                    similarity
                )
        
        # Sort by weighted score
        sorted_labels = sorted(
            label_scores.items(), 
            key=lambda x: x[1]['score'], 
            reverse=True
        )
        
        # Create predictions
        predictions = []
        for label, data in sorted_labels[:top_k]:
            predictions.append({
                'label': label,
                'confidence': data['max_similarity'],  # Use max similarity as confidence
                'support': data['count'],  # How many similar companies had this label
                'avg_similarity': data['score'] / data['count']
            })
        
        # Primary prediction
        if predictions:
            primary = predictions[0]
            result = {
                'primary_prediction': primary['label'],
                'primary_confidence': primary['confidence'],
                'predictions': predictions,
                'similar_companies': similar_companies[:5],  # Include some examples
                'method': 'similarity-based'
            }
        else:
            result = {
                'primary_prediction': 'Unknown',
                'primary_confidence': 0.0,
                'predictions': [],
                'similar_companies': similar_companies[:5],
                'method': 'similarity-based'
            }
        
        return result
    
    def evaluate_approach(self):
        """Test the similarity approach on some examples"""
        print("\nüß™ TESTING SIMILARITY-BASED APPROACH")
        print("=" * 60)
        
        test_cases = [
            {
                'name': 'Software Company',
                'description': 'Software development company building web applications and mobile apps',
                'business_tags': ['Software Development', 'Web Development', 'Mobile Apps']
            },
            {
                'name': 'Restaurant',
                'description': 'Italian restaurant serving authentic cuisine in downtown location',
                'business_tags': ['Restaurant', 'Food Service', 'Italian Cuisine']
            },
            {
                'name': 'Manufacturing',
                'description': 'Manufacturing facility producing automotive parts and components',
                'business_tags': ['Manufacturing', 'Automotive Parts', 'Production']
            }
        ]
        
        for test in test_cases:
            print(f"\nüìä Test: {test['name']}")
            result = self.predict(test)
            
            print(f"Primary prediction: {result['primary_prediction']}")
            print(f"Confidence: {result['primary_confidence']:.3f}")
            
            print("\nTop predictions:")
            for i, pred in enumerate(result['predictions'][:3], 1):
                print(f"  {i}. {pred['label']} (similarity: {pred['confidence']:.3f}, "
                      f"found in {pred['support']} similar companies)")
            
            print("\nMost similar companies:")
            for i, company in enumerate(result['similar_companies'][:3], 1):
                print(f"  {i}. {company['label']} - {company['sector']}")
                print(f"     Similarity: {company['similarity']:.3f}")
                print(f"     Description: {company['description']}")
        
        return True


def compare_approaches():
    """Compare the classification vs similarity approach"""
    print("üìä COMPARING APPROACHES")
    print("=" * 60)
    
    print("\n‚ùå CLASSIFICATION APPROACH (908 labels):")
    print("  ‚Ä¢ Mathematically impossible with 2.6 examples per label")
    print("  ‚Ä¢ 59% of labels have only 1 example")
    print("  ‚Ä¢ Model just memorizes, doesn't generalize")
    print("  ‚Ä¢ Predictions are random noise")
    
    print("\n‚úÖ SIMILARITY APPROACH:")
    print("  ‚Ä¢ Finds similar companies based on description")
    print("  ‚Ä¢ Returns labels from similar companies")
    print("  ‚Ä¢ Works with any amount of data")
    print("  ‚Ä¢ Provides interpretable results")
    print("  ‚Ä¢ Shows which companies influenced the prediction")
    
    print("\nüéØ SIMILARITY ADVANTAGES:")
    print("  1. No training required - just similarity search")
    print("  2. Works with single examples")
    print("  3. Transparent - you see why it made the prediction")
    print("  4. Can handle new labels without retraining")
    print("  5. Confidence scores are meaningful (actual similarity)")


if __name__ == "__main__":
    # Show comparison
    compare_approaches()
    
    # Test similarity approach
    classifier = SimilarityBasedClassifier()
    classifier.evaluate_approach()
    
    print("\n‚úÖ This approach actually works with your sparse data!")
    print("üí° Consider collecting more examples only for your most important labels.") 